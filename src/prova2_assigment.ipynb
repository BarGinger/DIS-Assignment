{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create class Graph in order to compute similarity between communities\n",
    "class Graph(object):\n",
    "    def __init__(self, numNodes):\n",
    "        # Use a dictionary to store edges to create a CSR matrix when needed\n",
    "        self.numNodes = numNodes\n",
    "        self.edges = []\n",
    "\n",
    "    def addEdge(self, start, end):\n",
    "        # Add an edge to the list of edges\n",
    "        if (start, end) not in self.edges:\n",
    "            self.edges.append((start, end))\n",
    "\n",
    "    def removeEdge(self, start, end):\n",
    "        # Remove an edge from the list of edges\n",
    "        if (start, end) in self.edges:\n",
    "            self.edges.remove((start, end))\n",
    "        else: #check if edge exists to not compute error\n",
    "            print(f\"There is no edge between {start} and {end}\")\n",
    "\n",
    "    def containsEdge(self, start, end): #check if edge exists in general\n",
    "        return (start, end) in self.edges\n",
    "\n",
    "    def to_csr_matrix(self):\n",
    "        # Create the CSR representation from the list of edges\n",
    "        rows, cols = zip(*self.edges) if self.edges else ([], [])\n",
    "        data = [1] * len(self.edges)\n",
    "        csr_mat = csr_matrix((data, (rows, cols)), shape=(self.numNodes, self.numNodes))\n",
    "        return csr_mat\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.numNodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to create adjacency matrix for a community in CSR format to save space!\n",
    "# def create_adjacency_matrix(community, max_size):\n",
    "#     # Find all unique nodes in the community\n",
    "#     unique_nodes = list(set(node for edge in community for node in edge)) \n",
    "#     node_to_index = {node: i for i, node in enumerate(unique_nodes)} #need to have a list of indices\n",
    "\n",
    "#     # Initialize lists for the CSR representation\n",
    "#     rows = []\n",
    "#     cols = []\n",
    "#     data = []\n",
    "\n",
    "#     # Populate rows, cols, and data lists for non-zero elements\n",
    "#     for node1, node2 in community:\n",
    "#         index1 = node_to_index[node1]\n",
    "#         index2 = node_to_index[node2]\n",
    "#         rows.append(index1)\n",
    "#         cols.append(index2)\n",
    "#         data.append(1)\n",
    "\n",
    "#     # Create a CSR matrix using scipy\n",
    "#     actual_size = len(unique_nodes)\n",
    "#     csr_mat = csr_matrix((data, (rows, cols)), shape=(actual_size, actual_size))\n",
    "\n",
    "#     # If the actual size is smaller than max_size, pad the matrix with zeros\n",
    "#     if actual_size < max_size + 1:\n",
    "#         csr_mat.resize((max_size + 1, max_size + 1))\n",
    "\n",
    "    # Function to create adjacency matrix for a community in CSR format with weighted values of duration\n",
    "def create_adjacency_matrix(community, max_size):\n",
    "    # Find all unique nodes in the community\n",
    "    unique_nodes = list(set(node for edge in community for node in edge[:2]))\n",
    "    node_to_index = {node: i for i, node in enumerate(unique_nodes)} #need to have a list of indices\n",
    "\n",
    "    # Initialize lists for the CSR representation\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    # Populate rows, cols, and data lists for non-zero elements\n",
    "    for node1, node2, duration in community:\n",
    "        if node1 in node_to_index and node2 in node_to_index:\n",
    "            index1 = node_to_index[node1]\n",
    "            index2 = node_to_index[node2]\n",
    "\n",
    "            # Use the provided duration as the weight (convert to integer if necessary)\n",
    "            rows.append(index1)\n",
    "            cols.append(index2)\n",
    "            data.append(int(duration))\n",
    "\n",
    "    # Create a CSR matrix using scipy\n",
    "    actual_size = max_size + 1\n",
    "    csr_mat = csr_matrix((data, (rows, cols)), shape=(actual_size, actual_size))\n",
    "    return csr_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#ARI is particularly useful here because it is adjusted for chance. \n",
    "# random similarities between matrices are not overemphasized, giving a more reliable measure of similarity.\n",
    "\n",
    "# def compare_matrices(matrix1, matrix2, comparison_method=\"adjusted.rand\"):\n",
    "#     #converts the CSR matrices (sparse representations of weighted adjacency matrices) \n",
    "#     # to dense arrays, which are then flattened into 1D vectors.\n",
    "#     dense_matrix1 = matrix1.toarray().flatten()\n",
    "#     dense_matrix2 = matrix2.toarray().flatten()\n",
    "#     # this vector represents whether nodes are connected and the weight of the connection, \n",
    "#     # using the provided duration values as edge weights.\n",
    "#     # Use the selected comparison method\n",
    "#     if comparison_method == \"adjusted.rand\":\n",
    "#         similarity = adjusted_rand_score(dense_matrix1, dense_matrix2) #ARI compares these vectors, treating them as cluster labels.\n",
    "#         #ARI evaluates how well the two communities match in terms of both structure (which nodes are connected) \n",
    "#         #and the weights of these connections.\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported comparison method: {comparison_method}\")\n",
    "\n",
    "#     return similarity\n",
    "'''\n",
    "def compare_matrices(matrix1, matrix2, comparison_method=\"cosine\"):\n",
    "    # Converts the CSR matrices (sparse representations of weighted adjacency matrices)\n",
    "    # to dense arrays, which are then flattened into 1D vectors.\n",
    "    dense_matrix1 = matrix1.toarray().flatten()\n",
    "    dense_matrix2 = matrix2.toarray().flatten()\n",
    "\n",
    "    # Use cosine similarity as the comparison method\n",
    "    dense_matrix1 = dense_matrix1.reshape(1, -1)  # Reshape for cosine similarity calculation\n",
    "    dense_matrix2 = dense_matrix2.reshape(1, -1)\n",
    "    similarity = cosine_similarity(dense_matrix1, dense_matrix2)[0][0]\n",
    "\n",
    "    return similarity\n",
    "'''\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def compute_similarity_matrix_csr(A, B, max_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the similarity matrix between two CSR adjacency matrices A and B using iterative updates.\n",
    "    \"\"\"\n",
    "    # Initialize the similarity matrix with ones (dense format)\n",
    "    nA, nB = A.shape[0], B.shape[0]\n",
    "    X = np.ones((nA, nB))\n",
    "    \n",
    "    # Iterative updates\n",
    "    for _ in range(max_iter):\n",
    "        X_new = B @ X @ A.T + B.T @ X @ A\n",
    "        # Normalize using Frobenius norm\n",
    "        X_new /= np.linalg.norm(X_new, ord='fro')\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(X_new - X, ord='fro') < tol:\n",
    "            break\n",
    "        \n",
    "        X = X_new\n",
    "    \n",
    "    return X\n",
    "\n",
    "def compute_community_similarity_csr(comm1, comm2):\n",
    "    \"\"\"\n",
    "    Compute similarity score between two communities, where comm1 and comm2 are CSR adjacency matrices.\n",
    "    \"\"\"\n",
    "    # Convert the CSR matrices to dense format temporarily for processing\n",
    "    comm1_dense = comm1.toarray()\n",
    "    comm2_dense = comm2.toarray()\n",
    "\n",
    "    # Compute the similarity matrix\n",
    "    similarity_matrix = compute_similarity_matrix_csr(comm1_dense, comm2_dense)\n",
    "    \n",
    "    # Return the Frobenius norm of the similarity matrix as the score\n",
    "    similarity_score = np.linalg.norm(similarity_matrix, ord='fro')\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "# Example usage with CSR matrices for communities A and B\n",
    "\n",
    "\n",
    "\n",
    "# Test the function to ensure the cosine similarity is now correctly implemented\n",
    "#ARI can indirectly assess the degree of similarity between the edge weights. \n",
    "# If two matrices have similar edge structures but different weights, this will reflect in a lower ARI score.\n",
    "\n",
    "#ARI helps determine both structural similarity (which nodes are connected) \n",
    "# and weighted edge similarity (how strong the connections are)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Structural and Weighted Edge Similarity in This Code***\n",
    "\n",
    "The code provides both structural similarity and weighted edge similarity through the following steps:\n",
    "\n",
    "Structural Similarity:\n",
    "\n",
    "The adjacency matrix encodes which nodes are connected. \n",
    "By converting these matrices into vectors, **the positions of non-zero elements in these vectors represent the connections between nodes**.\n",
    "This code evaluates whether the matrices agree on the existence of edges between nodes, giving structural similarity.\n",
    "\n",
    "Weighted Edge Similarity:\n",
    "\n",
    "The weight of the edges is represented by the duration values in each tuple. \n",
    "When constructing the CSR matrix, **these durations become the actual values in the matrix**, rather than just indicating the presence or absence of a connection. (The code of this is still available, if we want to do 50/50 similarity comparison)\n",
    "\n",
    "By flattening the weighted adjacency matrix, ARI takes into account the weights when comparing two vectors. \n",
    "If the durations are different, it affects the overall similarity score. \n",
    "This reflects how strong or weak the edges are between corresponding nodes.\n",
    "Thus, ARI provides a metric for how similar the two graphs are not only based on their topology but also on the intensity of the connections.\n",
    "\n",
    "***Advantages***\n",
    "\n",
    "Handles Weighted Comparisons:\n",
    "\n",
    "In this core it **compares weighted vectors derived from adjacency matrices**.\n",
    "\n",
    "\n",
    "Robust Against Random Similarities:\n",
    "\n",
    "Since the ARI is adjusted for chance, it is more **robust against random structural similarities between different graphs**. This property makes it well-suited for assessing similarity between communities where the goal is to identify truly similar interaction patterns rather than coincidental connections.\n",
    "\n",
    "Single Measure of Similarity:\n",
    "\n",
    "ARI gives a single score that encapsulates both structural and weight similarities, making it a convenient metric for evaluating the overall similarity of two graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_list(list):\n",
    "    list_len = [len(i) for i in list]\n",
    "    return max(list_len)\n",
    "\n",
    "def print_similarity_score(communities):\n",
    "    # Find the maximum node index across all communities\n",
    "    max_node = max(max(edge[0], edge[1]) for community in communities for edge in community)\n",
    "    \n",
    "    # Create adjacency matrices for each community\n",
    "    matrices = [create_adjacency_matrix(community, max_node) for community in communities]\n",
    "    \n",
    "    # Loop through all pairs of communities and print similarity scores\n",
    "    for i, matrix1 in enumerate(matrices):\n",
    "        for j in range(i + 1, len(matrices)):  # Ensure j is within the valid range\n",
    "            matrix2 = matrices[j]\n",
    "            similarity = compute_community_similarity_csr(matrix1, matrix2)\n",
    "            print(f\"Score similarity between community {i} and {j} is:\")\n",
    "            print(similarity)\n",
    "\n",
    "def group_similar_communities(communities, threshold, max_size):\n",
    "    # Find the maximum node index across all communities\n",
    "    max_node = max(max(edge[0], edge[1]) for community in communities for edge in community)\n",
    "    \n",
    "    # Create CSR adjacency matrices for each community\n",
    "    matrices = [create_adjacency_matrix(community, max_node) for community in communities]\n",
    "    \n",
    "    # Initialize a list to hold grouped communities\n",
    "    groups = []\n",
    "    \n",
    "    # List to track communities that have been grouped\n",
    "    grouped = set()\n",
    "    \n",
    "    for i, matrix1 in enumerate(matrices):\n",
    "        if i in grouped:\n",
    "            continue\n",
    "        current_group = [communities[i]]\n",
    "        \n",
    "        for j in range(i + 1, min(len(matrices), max_size)):  # Compare i with every community after i, up to max_size\n",
    "            if j not in grouped:\n",
    "                matrix2 = matrices[j]\n",
    "                # Compute similarity between the two communities' adjacency matrices\n",
    "                similarity = compute_community_similarity_csr(matrix1, matrix2)  # CSR-based similarity function\n",
    "                \n",
    "                # Check if the similarity exceeds the threshold\n",
    "                if similarity >= threshold:\n",
    "                    current_group.append(communities[j])\n",
    "                    grouped.add(j)  # Mark as grouped to avoid reprocessing\n",
    "        \n",
    "        groups.append(current_group)\n",
    "\n",
    "    return groups\n",
    "# def group_similar_communities(communities, threshold):\n",
    "#     # Find the maximum node index across all communities\n",
    "#     max_node = max(max(edge[0], edge[1]) for community in communities for edge in community)\n",
    "    \n",
    "#     # Create adjacency matrices for each community\n",
    "#     matrices = [create_adjacency_matrix(community, max_node) for community in communities]\n",
    "    \n",
    "#     # Initialize a list to hold grouped communities\n",
    "#     groups = []\n",
    "    \n",
    "#     # List to track communities that have been grouped\n",
    "#     grouped = set()\n",
    "    \n",
    "#     for i, matrix1 in enumerate(matrices):\n",
    "#         if i in grouped:\n",
    "#             continue\n",
    "#         current_group = [communities[i]]\n",
    "#         for j in range(i + 1, len(matrices)):  # Compare i with every community after i\n",
    "#             matrix2 = matrices[j]\n",
    "#             similarity = compare_matrices(matrix1, matrix2)\n",
    "#             print(f\"Score similarity between community {i} and {j} is:\")\n",
    "#             print(similarity)\n",
    "#             if similarity >= threshold:\n",
    "#                 current_group.append(communities[j])\n",
    "#                 grouped.add(j)  # Mark as grouped to avoid reprocessing\n",
    "#         groups.append(current_group)\n",
    "\n",
    "#     # Ensure all remaining ungrouped communities are printed\n",
    "#     for i in range(len(matrices)):\n",
    "#         for j in range(i + 1, len(matrices)):\n",
    "#             similarity = compare_matrices(matrices[i], matrices[j])\n",
    "#             print(f\"Score similarity between community {i} and {j} is:\")\n",
    "#             print(similarity)\n",
    "    \n",
    "#     return groups\n",
    "\n",
    "# Run the function and test the similarity scoring\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score similarity between community 0 and 1 is:\n",
      "0.9999999999999999\n",
      "Score similarity between community 0 and 2 is:\n",
      "1.0\n",
      "Score similarity between community 0 and 3 is:\n",
      "1.0\n",
      "Score similarity between community 1 and 2 is:\n",
      "0.9999999999999999\n",
      "Score similarity between community 1 and 3 is:\n",
      "0.9999999999999999\n",
      "Score similarity between community 2 and 3 is:\n",
      "1.0\n",
      "Group 1: [[(1, 2, '000002'), (2, 3, '000005')], [(4, 5, '000006'), (5, 6, '000015'), (6, 7, '000008')], [(8, 9, '000103'), (9, 10, '001005'), (10, 11, '000204')], [(12, 13, '000002'), (13, 14, '000005'), (14, 12, '000008')]]\n"
     ]
    }
   ],
   "source": [
    "# Example of how you would use this with community data\n",
    "# communities = [\n",
    "#     [(0, 1), (1, 2)],        # Community 1\n",
    "#     [(10, 11), (11, 13), (13, 14)],  # Community 2\n",
    "#     [(4, 5), (5, 6)],         # Community 3\n",
    "#     [(7, 8)],                 # Community 4\n",
    "# ]\n",
    "\n",
    "# communities = [\n",
    "#     [(0, 1, '001530'), (1, 2, '001645')],                   # Community 1\n",
    "#     [(10, 11, '001130'), (11, 13, '001245'), (13, 14, '001315')],  # Community 2\n",
    "#     [(4, 5, '000945'), (5, 6, '001030')],                   # Community 3\n",
    "#     [(7, 8, '011200')],                                     # Community 4\n",
    "# ]\n",
    "communities = [\n",
    "    [(1, 2, '000002'), (2, 3, '000005')],  # Community 13\n",
    "    [(4, 5, '000006'), (5, 6, '000015'), (6, 7, '000008')],  # Community 4\n",
    "    [(8, 9, '000103'), (9, 10, '001005'), (10, 11, '000204')],  # Community 10\n",
    "    [(12, 13, '000002'), (13,14,'000005'), (14, 12, '000008')]  # Community 1\n",
    "\n",
    "]\n",
    "\n",
    "print_similarity_score(communities)\n",
    "# Group communities based on 60% similarity\n",
    "similar_communities = group_similar_communities(communities, threshold=0.9, max_size=len(communities))\n",
    "\n",
    "# Print the results\n",
    "for idx,group in enumerate(similar_communities):\n",
    "    print(f\"Group {idx + 1}: {group}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
