{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarGinger/DIS-Assignment/blob/main/Src/dis_notebook_25_10_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFDENKMNs-52",
        "outputId": "0e87e243-2e14-4c6d-fa78-9d8818dcee14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "openjdk-8-jdk-headless is already the newest version (8u422-b05-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: graphframes in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.26.4)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.3.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "!pip install graphframes\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import (\n",
        "    col,\n",
        "    udf,\n",
        "    row_number,\n",
        "    countDistinct,\n",
        "    collect_list,\n",
        "    struct,\n",
        "    count,\n",
        "    sum,\n",
        "    avg,\n",
        "    expr,\n",
        "    percentile_approx,\n",
        "    max as spark_max\n",
        ")\n",
        "from pyspark.sql.types import StringType, IntegerType, BinaryType, DoubleType, ArrayType, StructType, StructField\n",
        "from pyspark.sql import Window\n",
        "from datetime import datetime\n",
        "from graphframes import GraphFrame\n",
        "from scipy.sparse import csr_matrix, vstack, hstack\n",
        "import numpy as np\n",
        "import pickle\n",
        "import base64"
      ],
      "metadata": {
        "id": "gjrP64v5QyEd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PhoneCallsCommunityDetection\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.1-s_2.12\") \\\n",
        "    .config(\"spark.executor.memory\", \"20G\") \\\n",
        "    .config(\"spark.driver.memory\", \"50G\") \\\n",
        "    .config(\"spark.executor.memoryOverhead\", \"1G\") \\\n",
        "    .config(\"spark.default.parallelism\", \"100\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"10\") \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Optional: Set logging level to reduce verbosity\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "# Set a checkpoint directory for Spark\n",
        "spark.sparkContext.setCheckpointDir(\"/tmp/spark-checkpoints\")\n",
        "\n",
        "file_path = 'toy_dataset.csv' #'adjusted_phone_calls.csv'\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Convert YYMMDDHHMM to a proper datetime object\n",
        "def convert_to_datetime(yyMMddHHMM):\n",
        "    return datetime.strptime(str(yyMMddHHMM), '%y%m%d%H%M')\n",
        "\n",
        "# Define UDF for calculating duration in minutes\n",
        "def calculate_duration_minutes(start_time, end_time):\n",
        "    start_dt = convert_to_datetime(start_time)\n",
        "    end_dt = convert_to_datetime(end_time)\n",
        "    duration = end_dt - start_dt\n",
        "    return duration.total_seconds() / 60\n",
        "\n",
        "# Define UDF for calculating duration in DDHHMM format\n",
        "def calculate_duration_string(start_time, end_time):\n",
        "    start_dt = convert_to_datetime(start_time)\n",
        "    end_dt = convert_to_datetime(end_time)\n",
        "    duration = end_dt - start_dt\n",
        "\n",
        "    days = duration.days\n",
        "    hours, remainder = divmod(duration.seconds, 3600)\n",
        "    minutes = remainder // 60\n",
        "    return f'{days:02d}{hours:02d}{minutes:02d}'\n",
        "\n",
        "# Register the UDFs in Spark\n",
        "calculate_duration_minutes_udf = udf(calculate_duration_minutes, DoubleType())\n",
        "calculate_duration_string_udf = udf(calculate_duration_string, StringType())\n",
        "\n",
        "# Add columns for duration in minutes and DDHHMM format\n",
        "df = df.withColumn('duration_minutes', calculate_duration_minutes_udf(col('Start_Time'), col('End_Time')))\n",
        "df = df.withColumn('duration_DDHHMM', calculate_duration_string_udf(col('Start_Time'), col('End_Time')))\n",
        "df.show()"
      ],
      "metadata": {
        "id": "RAMTvsL2v2YH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9483f032-0a25-4cca-d1ac-8acc5c37dfd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+----------+----------+----------------+---------------+\n",
            "|Client1|Client2|Start_Time|  End_Time|duration_minutes|duration_DDHHMM|\n",
            "+-------+-------+----------+----------+----------------+---------------+\n",
            "|      1|      2|2408060000|2408060200|           120.0|         000200|\n",
            "|      2|      3|2408040000|2408040500|           300.0|         000500|\n",
            "|      4|      5|2408020000|2408020600|           360.0|         000600|\n",
            "|      5|      6|2408090000|2408091500|           900.0|         001500|\n",
            "|      6|      7|2408070000|2408070800|           480.0|         000800|\n",
            "|      8|      9|2408090000|2408090300|           180.0|         000300|\n",
            "|      9|     10|2408070000|2408070500|           300.0|         000500|\n",
            "|     10|     11|2408010000|2408010400|           240.0|         000400|\n",
            "|     12|     13|2408010000|2408010200|           120.0|         000200|\n",
            "|     13|     14|2408030000|2408030500|           300.0|         000500|\n",
            "|     12|     14|2408020000|2408020800|           480.0|         000800|\n",
            "+-------+-------+----------+----------+----------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Graph using GraphFrames for community detection\n",
        "vertices = df.selectExpr(\"Client1 as id\").union(df.selectExpr(\"Client2 as id\")).distinct()\n",
        "edges = df.selectExpr(\"Client1 as src\", \"Client2 as dst\", \"duration_minutes as weight\")\n",
        "\n",
        "# Cache vertices and edges\n",
        "vertices.cache()\n",
        "edges.cache()\n",
        "\n",
        "# Create a GraphFrame\n",
        "g = GraphFrame(vertices, edges)\n",
        "\n",
        "# Find connected components (communities) using GraphFrames\n",
        "result = g.connectedComponents()\n",
        "\n",
        "# Create a mapping from original community IDs to sequential ones\n",
        "community_mapping = result.select(\"component\").distinct() \\\n",
        "    .orderBy(\"component\") \\\n",
        "    .withColumn(\"new_id\", row_number().over(Window.orderBy(\"component\"))) \\\n",
        "    .cache()\n",
        "\n",
        "# Join the result (community IDs) with the original dataframe and map to new sequential IDs\n",
        "df_with_communities = df.join(result, df['Client1'] == result['id'], 'inner') \\\n",
        "    .join(community_mapping, result['component'] == community_mapping['component'], 'inner') \\\n",
        "    .drop(result['id']) \\\n",
        "    .drop(community_mapping['component']) \\\n",
        "    .withColumnRenamed('new_id', 'community_id')\n",
        "\n",
        "# Calculate the number of unique clients (community size) per community\n",
        "community_sizes = df_with_communities.select(\"community_id\", \"Client1\").union(df_with_communities.select(\"community_id\", \"Client2\")) \\\n",
        "    .distinct() \\\n",
        "    .groupBy(\"community_id\").agg(countDistinct(\"Client1\").alias(\"community_size\"))\n",
        "\n",
        "# Merge the community sizes into the main DataFrame\n",
        "df_final = df_with_communities.join(community_sizes, 'community_id')\n",
        "\n",
        "# Get list of tuples for each community member by considering both Client1 and Client2\n",
        "community_members = df_final.select(\"community_id\", \"Client1\", \"Client2\", \"duration_DDHHMM\", \"duration_minutes\") \\\n",
        "    .distinct() \\\n",
        "    .groupBy(\"community_id\") \\\n",
        "    .agg(collect_list(struct(col(\"Client1\"),\n",
        "                           col(\"Client2\"),\n",
        "                           col(\"duration_DDHHMM\"),\n",
        "                           col(\"duration_minutes\"))).alias(\"members\")) \\\n",
        "    .orderBy(\"community_id\")\n",
        "\n",
        "# Show the final DataFrame with community IDs, duration, and community sizes\n",
        "print(\"\\nFinal DataFrame with Sequential Community IDs:\")\n",
        "df_final.select('Client1',\n",
        "                'Client2',\n",
        "                'duration_DDHHMM',\n",
        "                'duration_minutes',\n",
        "                'community_id',\n",
        "                'community_size') \\\n",
        "    .orderBy(\"community_id\") \\\n",
        "    .show()\n",
        "\n",
        "# Show the list of community members as tuples\n",
        "print(\"\\nCommunity Members with Sequential IDs:\")\n",
        "community_members.show(truncate=False)\n",
        "\n",
        "# Save results to CSV files\n",
        "# Save the main analysis results\n",
        "df_final.select('Client1',\n",
        "                'Client2',\n",
        "                'duration_DDHHMM',\n",
        "                'duration_minutes',\n",
        "                'community_id',\n",
        "                'community_size') \\\n",
        "    .orderBy(\"community_id\") \\\n",
        "    .write.mode(\"overwrite\").csv(\"community_analysis_results\")\n",
        "\n",
        "# Save community members in a flattened format\n",
        "df_final.select('community_id',\n",
        "                'Client1',\n",
        "                'Client2',\n",
        "                'duration_DDHHMM',\n",
        "                'duration_minutes') \\\n",
        "    .distinct() \\\n",
        "    .orderBy(\"community_id\") \\\n",
        "    .write.mode(\"overwrite\").csv(\"community_members_results\")\n",
        "\n",
        "# Optionally, if you want to save additional community statistics\n",
        "community_stats = df_final.groupBy('community_id') \\\n",
        "    .agg(\n",
        "        countDistinct('Client1', 'Client2').alias('unique_members'),\n",
        "        count('*').alias('total_calls'),\n",
        "        sum('duration_minutes').alias('total_duration_minutes'),\n",
        "        avg('duration_minutes').alias('avg_call_duration'),\n",
        "        percentile_approx('duration_minutes', 0.25).alias('duration_25th_percentile'),\n",
        "        percentile_approx('duration_minutes', 0.5).alias('median_call_duration'),\n",
        "        percentile_approx('duration_minutes', 0.75).alias('duration_75th_percentile')\n",
        "    ) \\\n",
        "    .orderBy('community_id')\n",
        "\n",
        "community_stats.write.mode(\"overwrite\").csv(\"community_statistics_results\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k10Ux9bh-zMO",
        "outputId": "755c443a-b489-4e00-b8f9-ff73190e0c3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final DataFrame with Sequential Community IDs:\n",
            "+-------+-------+---------------+----------------+------------+--------------+\n",
            "|Client1|Client2|duration_DDHHMM|duration_minutes|community_id|community_size|\n",
            "+-------+-------+---------------+----------------+------------+--------------+\n",
            "|      1|      2|         000200|           120.0|           1|             3|\n",
            "|      2|      3|         000500|           300.0|           1|             3|\n",
            "|      4|      5|         000600|           360.0|           2|             4|\n",
            "|      5|      6|         001500|           900.0|           2|             4|\n",
            "|      6|      7|         000800|           480.0|           2|             4|\n",
            "|     10|     11|         000400|           240.0|           3|             4|\n",
            "|      8|      9|         000300|           180.0|           3|             4|\n",
            "|      9|     10|         000500|           300.0|           3|             4|\n",
            "|     12|     14|         000800|           480.0|           4|             3|\n",
            "|     12|     13|         000200|           120.0|           4|             3|\n",
            "|     13|     14|         000500|           300.0|           4|             3|\n",
            "+-------+-------+---------------+----------------+------------+--------------+\n",
            "\n",
            "\n",
            "Community Members with Sequential IDs:\n",
            "+------------+---------------------------------------------------------------------------+\n",
            "|community_id|members                                                                    |\n",
            "+------------+---------------------------------------------------------------------------+\n",
            "|1           |[{2, 3, 000500, 300.0}, {1, 2, 000200, 120.0}]                             |\n",
            "|2           |[{6, 7, 000800, 480.0}, {5, 6, 001500, 900.0}, {4, 5, 000600, 360.0}]      |\n",
            "|3           |[{9, 10, 000500, 300.0}, {8, 9, 000300, 180.0}, {10, 11, 000400, 240.0}]   |\n",
            "|4           |[{13, 14, 000500, 300.0}, {12, 13, 000200, 120.0}, {12, 14, 000800, 480.0}]|\n",
            "+------------+---------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "community_members.show(truncate=False)"
      ],
      "metadata": {
        "id": "JJ8vALJnJpAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_csr_matrix_from_edges_with_spark(members_df):\n",
        "    \"\"\"\n",
        "    Creates a CSR matrix from a Spark DataFrame based on unique vertices.\n",
        "\n",
        "    Args:\n",
        "        members_df: Spark DataFrame with 'community_id' and 'members' columns.\n",
        "\n",
        "    Returns:\n",
        "        A CSR matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    # Explode the members array to get each connection in separate rows\n",
        "    exploded_df = members_df.select(\n",
        "        \"community_id\",\n",
        "        explode(\"members\").alias(\"member\")\n",
        "    ).select(\n",
        "        \"community_id\",\n",
        "        col(\"member.Client1\").alias(\"Client1\"),\n",
        "        col(\"member.Client2\").alias(\"Client2\"),\n",
        "        col(\"member.duration_minutes\").alias(\"duration_minutes\")\n",
        "    )\n",
        "\n",
        "    # Get unique clients and create a mapping to indices\n",
        "    unique_clients = exploded_df.select(\"Client1\").union(exploded_df.select(\"Client2\")).distinct().rdd.flatMap(lambda x: x).collect()\n",
        "    client_to_index = {client: i for i, client in enumerate(unique_clients)}\n",
        "    num_clients = len(unique_clients)\n",
        "\n",
        "    # Extract data for CSR matrix\n",
        "    rows = exploded_df.select(\"Client1\").rdd.map(lambda row: client_to_index[row[0]]).collect()\n",
        "    cols = exploded_df.select(\"Client2\").rdd.map(lambda row: client_to_index[row[0]]).collect()\n",
        "    data = exploded_df.select(\"duration_minutes\").rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "    # Create CSR matrix\n",
        "    csr = csr_matrix((data, (rows, cols)), shape=(num_clients, num_clients))\n",
        "\n",
        "    return csr\n",
        "\n",
        "# Create CSR matrix\n",
        "csr_matrix_result = create_csr_matrix_from_edges(community_members)\n",
        "\n",
        "# Print some information about the matrix\n",
        "print(f\"CSR Matrix shape: {csr_matrix_result.shape}\")\n",
        "print(f\"Number of non-zero elements: {csr_matrix_result.nnz}\")"
      ],
      "metadata": {
        "id": "lWB3dqK0qOgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print csr_matrix_result pretty\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def pretty_print_csr_matrix(csr_matrix_result):\n",
        "  \"\"\"Prints a CSR matrix in a readable format.\"\"\"\n",
        "\n",
        "  rows, cols = csr_matrix_result.nonzero()\n",
        "  data = csr_matrix_result.data\n",
        "\n",
        "  df = pd.DataFrame({\n",
        "      'Row': rows,\n",
        "      'Col': cols,\n",
        "      'Value': data\n",
        "  })\n",
        "\n",
        "  print(df)\n",
        "\n",
        "\n",
        "pretty_print_csr_matrix(csr_matrix_result)"
      ],
      "metadata": {
        "id": "FwBOu_C9tleA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a test for create_csr_matrix_from_edges\n",
        "\n",
        "import unittest\n",
        "from scipy.sparse import csr_matrix\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import explode, col\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
        "\n",
        "# Assuming you have the necessary Spark environment and community_members DataFrame\n",
        "\n",
        "class TestCreateCsrMatrixFromEdges(unittest.TestCase):\n",
        "    def test_create_csr_matrix_from_edges(self):\n",
        "        # Create a sample DataFrame for testing\n",
        "        schema = StructType([\n",
        "            StructField(\"community_id\", StringType(), True),\n",
        "            StructField(\"members\", ArrayType(\n",
        "                StructType([\n",
        "                    StructField(\"Client1\", StringType(), True),\n",
        "                    StructField(\"Client2\", StringType(), True),\n",
        "                    StructField(\"duration_DDHHMM\", StringType(), True),\n",
        "                    StructField(\"duration_minutes\", DoubleType(), True)\n",
        "                ])\n",
        "            ), True)\n",
        "        ])\n",
        "        data = [\n",
        "            (1, [\n",
        "                {\"Client1\": \"A\", \"Client2\": \"B\", \"duration_DDHHMM\": \"000100\", \"duration_minutes\": 10.0},\n",
        "                {\"Client1\": \"B\", \"Client2\": \"C\", \"duration_DDHHMM\": \"000030\", \"duration_minutes\": 30.0}\n",
        "            ]),\n",
        "            (2, [\n",
        "                {\"Client1\": \"D\", \"Client2\": \"E\", \"duration_DDHHMM\": \"000015\", \"duration_minutes\": 15.0}\n",
        "            ])\n",
        "        ]\n",
        "\n",
        "        members_df = spark.createDataFrame(data, schema=schema)\n",
        "\n",
        "        # Expected CSR matrix\n",
        "        expected_csr = csr_matrix(\n",
        "            ([10.0, 30.0, 15.0], ([0, 1, 3], [1, 2, 4])),\n",
        "            shape=(5, 5)\n",
        "        )\n",
        "\n",
        "        # Call the function to create the CSR matrix\n",
        "        csr_matrix_result = create_csr_matrix_from_edges(members_df)\n",
        "\n",
        "        # Assert the matrix shape and data\n",
        "        self.assertEqual(csr_matrix_result.shape, expected_csr.shape)\n",
        "        self.assertTrue((csr_matrix_result.toarray() == expected_csr.toarray()).all())\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "id": "cs09k0kIt9ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSR adjacency matrices for each community and serialize them\n",
        "def create_csr_matrix(members, use_weights=False):\n",
        "    clients = list(set([member['Client1'] for member in members] + [member['Client2'] for member in members]))\n",
        "    client_index = {client: idx for idx, client in enumerate(clients)}\n",
        "\n",
        "    row_indices = []\n",
        "    col_indices = []\n",
        "    data = []\n",
        "\n",
        "    for member in members:\n",
        "        row_indices.append(client_index[member['Client1']])\n",
        "        col_indices.append(client_index[member['Client2']])\n",
        "        if use_weights:\n",
        "            data.append(float(member['duration_minutes']))  # Use duration in minutes as the weight of the edge\n",
        "        else:\n",
        "            data.append(1)  # Use 1 for unweighted similarity\n",
        "\n",
        "    num_clients = len(clients)\n",
        "    csr = csr_matrix((data, (row_indices, col_indices)), shape=(num_clients, num_clients))\n",
        "\n",
        "    # Serialize the CSR matrix\n",
        "    serialized_csr = base64.b64encode(pickle.dumps(csr)).decode('utf-8')\n",
        "    return serialized_csr"
      ],
      "metadata": {
        "id": "SLVvHeMPPduW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the collected list of Row objects to a list of dictionaries before passing to UDF\n",
        "schema = StructType([\n",
        "    StructField(\"Client1\", StringType(), True),\n",
        "    StructField(\"Client2\", StringType(), True),\n",
        "    StructField(\"duration_DDHHMM\", StringType(), True),\n",
        "    StructField(\"duration_minutes\", DoubleType(), True)\n",
        "])\n",
        "convert_members_udf = udf(lambda members: [member.asDict() for member in members], ArrayType(schema))\n",
        "community_members = community_members.withColumn(\"members_dict\", convert_members_udf(col(\"members\")))\n",
        "#Register UDF to create and serialize CSR matrices (both unweighted and weighted)\n",
        "create_csr_unweighted_udf = udf(lambda members: create_csr_matrix(members, use_weights=False), StringType())\n",
        "create_csr_weighted_udf = udf(lambda members: create_csr_matrix(members, use_weights=True), StringType())\n",
        "\n",
        "# Add CSR matrix representations (unweighted and weighted) to each community\n",
        "community_members = community_members.withColumn(\"csr_matrix_unweighted\", create_csr_unweighted_udf(col(\"members_dict\")))\n",
        "community_members = community_members.withColumn(\"csr_matrix_weighted\", create_csr_weighted_udf(col(\"members_dict\")))\n",
        "\n",
        "community_members.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjuHFxkPcriO",
        "outputId": "8449ed10-18d8-4988-ea6b-89af27c71819"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|community_id|members                                                                    |members_dict                                                               |csr_matrix_unweighted                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |csr_matrix_weighted                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "+------------+---------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1           |[{2, 3, 000500, 300.0}, {1, 2, 000200, 120.0}]                             |[{2, 3, 000500, 300.0}, {1, 2, 000200, 120.0}]                             |gASVnwEAAAAAAACMEXNjaXB5LnNwYXJzZS5fY3NylIwKY3NyX21hdHJpeJSTlCmBlH2UKIwGX3NoYXBllEsDSwOGlIwIbWF4cHJpbnSUSzKMBmluZHB0cpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMDF9yZWNvbnN0cnVjdJSTlIwFbnVtcHmUjAduZGFycmF5lJOUSwCFlEMBYpSHlFKUKEsBSwSFlGgMjAVkdHlwZZSTlIwCaTSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYolDEAAAAAABAAAAAgAAAAIAAACUdJRijAdpbmRpY2VzlGgLaA5LAIWUaBCHlFKUKEsBSwKFlGgYiUMIAQAAAAIAAACUdJRijARkYXRhlGgLaA5LAIWUaBCHlFKUKEsBSwKFlGgVjAJpOJSJiIeUUpQoSwNoGU5OTkr/////Sv////9LAHSUYolDEAEAAAAAAAAAAQAAAAAAAACUdJRijBVfaGFzX2Nhbm9uaWNhbF9mb3JtYXSUiIwTX2hhc19zb3J0ZWRfaW5kaWNlc5SIdWIu                        |gASVnwEAAAAAAACMEXNjaXB5LnNwYXJzZS5fY3NylIwKY3NyX21hdHJpeJSTlCmBlH2UKIwGX3NoYXBllEsDSwOGlIwIbWF4cHJpbnSUSzKMBmluZHB0cpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMDF9yZWNvbnN0cnVjdJSTlIwFbnVtcHmUjAduZGFycmF5lJOUSwCFlEMBYpSHlFKUKEsBSwSFlGgMjAVkdHlwZZSTlIwCaTSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYolDEAAAAAABAAAAAgAAAAIAAACUdJRijAdpbmRpY2VzlGgLaA5LAIWUaBCHlFKUKEsBSwKFlGgYiUMIAQAAAAIAAACUdJRijARkYXRhlGgLaA5LAIWUaBCHlFKUKEsBSwKFlGgVjAJmOJSJiIeUUpQoSwNoGU5OTkr/////Sv////9LAHSUYolDEAAAAAAAAF5AAAAAAADAckCUdJRijBVfaGFzX2Nhbm9uaWNhbF9mb3JtYXSUiIwTX2hhc19zb3J0ZWRfaW5kaWNlc5SIdWIu                        |\n",
            "|2           |[{6, 7, 000800, 480.0}, {5, 6, 001500, 900.0}, {4, 5, 000600, 360.0}]      |[{6, 7, 000800, 480.0}, {5, 6, 001500, 900.0}, {4, 5, 000600, 360.0}]      |gASVrwEAAAAAAACMEXNjaXB5LnNwYXJzZS5fY3NylIwKY3NyX21hdHJpeJSTlCmBlH2UKIwGX3NoYXBllEsESwSGlIwIbWF4cHJpbnSUSzKMBmluZHB0cpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMDF9yZWNvbnN0cnVjdJSTlIwFbnVtcHmUjAduZGFycmF5lJOUSwCFlEMBYpSHlFKUKEsBSwWFlGgMjAVkdHlwZZSTlIwCaTSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYolDFAAAAAABAAAAAgAAAAMAAAADAAAAlHSUYowHaW5kaWNlc5RoC2gOSwCFlGgQh5RSlChLAUsDhZRoGIlDDAEAAAACAAAAAwAAAJR0lGKMBGRhdGGUaAtoDksAhZRoEIeUUpQoSwFLA4WUaBWMAmk4lImIh5RSlChLA2gZTk5OSv////9K/////0sAdJRiiUMYAQAAAAAAAAABAAAAAAAAAAEAAAAAAAAAlHSUYowVX2hhc19jYW5vbmljYWxfZm9ybWF0lIiME19oYXNfc29ydGVkX2luZGljZXOUiHViLg==|gASVrwEAAAAAAACMEXNjaXB5LnNwYXJzZS5fY3NylIwKY3NyX21hdHJpeJSTlCmBlH2UKIwGX3NoYXBllEsESwSGlIwIbWF4cHJpbnSUSzKMBmluZHB0cpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMDF9yZWNvbnN0cnVjdJSTlIwFbnVtcHmUjAduZGFycmF5lJOUSwCFlEMBYpSHlFKUKEsBSwWFlGgMjAVkdHlwZZSTlIwCaTSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYolDFAAAAAABAAAAAgAAAAMAAAADAAAAlHSUYowHaW5kaWNlc5RoC2gOSwCFlGgQh5RSlChLAUsDhZRoGIlDDAEAAAACAAAAAwAAAJR0lGKMBGRhdGGUaAtoDksAhZRoEIeUUpQoSwFLA4WUaBWMAmY4lImIh5RSlChLA2gZTk5OSv////9K/////0sAdJRiiUMYAAAAAACAdkAAAAAAACCMQAAAAAAAAH5AlHSUYowVX2hhc19jYW5vbmljYWxfZm9ybWF0lIiME19oYXNfc29ydGVkX2luZGljZXOUiHViLg==|\n",
            "|3           |[{9, 10, 000500, 300.0}, {8, 9, 000300, 180.0}, {10, 11, 000400, 240.0}]   |[{9, 10, 000500, 300.0}, {8, 9, 000300, 180.0}, {10, 11, 000400, 240.0}]   |gASVrwEAAAAAAACMEXNjaXB5LnNwYXJzZS5fY3NylIwKY3NyX21hdHJpeJSTlCmBlH2UKIwGX3NoYXBllEsESwSGlIwIbWF4cHJpbnSUSzKMBmluZHB0cpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMDF9yZWNvbnN0cnVjdJSTlIwFbnVtcHmUjAduZGFycmF5lJOUSwCFlEMBYpSHlFKUKEsBSwWFlGgMjAVkdHlwZZSTlIwCaTSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYolDFAAAAAABAAAAAgAAAAMAAAADAAAAlHSUYowHaW5kaWNlc5RoC2gOSwCFlGgQh5RSlChLAUsDhZRoGIlDDAEAAAACAAAAAwAAAJR0lGKMBGRhdGGUaAtoDksAhZRoEIeUUpQoSwFLA4WUaBWMAmk4lImIh5RSlChLA2gZTk5OSv////9K/////0sAdJRiiUMYAQAAAAAAAAABAAAAAAAAAAEAAAAAAAAAlHSUYowVX2hhc19jYW5vbmljYWxfZm9ybWF0lIiME19oYXNfc29ydGVkX2luZGljZXOUiHViLg==|gASVrwEAAAAAAACMEXNjaXB5LnNwYXJzZS5fY3NylIwKY3NyX21hdHJpeJSTlCmBlH2UKIwGX3NoYXBllEsESwSGlIwIbWF4cHJpbnSUSzKMBmluZHB0cpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMDF9yZWNvbnN0cnVjdJSTlIwFbnVtcHmUjAduZGFycmF5lJOUSwCFlEMBYpSHlFKUKEsBSwWFlGgMjAVkdHlwZZSTlIwCaTSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYolDFAAAAAABAAAAAgAAAAMAAAADAAAAlHSUYowHaW5kaWNlc5RoC2gOSwCFlGgQh5RSlChLAUsDhZRoGIlDDAEAAAACAAAAAwAAAJR0lGKMBGRhdGGUaAtoDksAhZRoEIeUUpQoSwFLA4WUaBWMAmY4lImIh5RSlChLA2gZTk5OSv////9K/////0sAdJRiiUMYAAAAAACAZkAAAAAAAMByQAAAAAAAAG5AlHSUYowVX2hhc19jYW5vbmljYWxfZm9ybWF0lIiME19oYXNfc29ydGVkX2luZGljZXOUiHViLg==|\n",
            "|4           |[{13, 14, 000500, 300.0}, {12, 13, 000200, 120.0}, {12, 14, 000800, 480.0}]|[{13, 14, 000500, 300.0}, {12, 13, 000200, 120.0}, {12, 14, 000800, 480.0}]|gASVqwEAAAAAAACMEXNjaXB5LnNwYXJzZS5fY3NylIwKY3NyX21hdHJpeJSTlCmBlH2UKIwGX3NoYXBllEsDSwOGlIwIbWF4cHJpbnSUSzKMBmluZHB0cpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMDF9yZWNvbnN0cnVjdJSTlIwFbnVtcHmUjAduZGFycmF5lJOUSwCFlEMBYpSHlFKUKEsBSwSFlGgMjAVkdHlwZZSTlIwCaTSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYolDEAAAAAACAAAAAwAAAAMAAACUdJRijAdpbmRpY2VzlGgLaA5LAIWUaBCHlFKUKEsBSwOFlGgYiUMMAQAAAAIAAAACAAAAlHSUYowEZGF0YZRoC2gOSwCFlGgQh5RSlChLAUsDhZRoFYwCaTiUiYiHlFKUKEsDaBlOTk5K/////0r/////SwB0lGKJQxgBAAAAAAAAAAEAAAAAAAAAAQAAAAAAAACUdJRijBVfaGFzX2Nhbm9uaWNhbF9mb3JtYXSUiIwTX2hhc19zb3J0ZWRfaW5kaWNlc5SIdWIu        |gASVqwEAAAAAAACMEXNjaXB5LnNwYXJzZS5fY3NylIwKY3NyX21hdHJpeJSTlCmBlH2UKIwGX3NoYXBllEsDSwOGlIwIbWF4cHJpbnSUSzKMBmluZHB0cpSMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMDF9yZWNvbnN0cnVjdJSTlIwFbnVtcHmUjAduZGFycmF5lJOUSwCFlEMBYpSHlFKUKEsBSwSFlGgMjAVkdHlwZZSTlIwCaTSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYolDEAAAAAACAAAAAwAAAAMAAACUdJRijAdpbmRpY2VzlGgLaA5LAIWUaBCHlFKUKEsBSwOFlGgYiUMMAQAAAAIAAAACAAAAlHSUYowEZGF0YZRoC2gOSwCFlGgQh5RSlChLAUsDhZRoFYwCZjiUiYiHlFKUKEsDaBlOTk5K/////0r/////SwB0lGKJQxgAAAAAAABeQAAAAAAAAH5AAAAAAADAckCUdJRijBVfaGFzX2Nhbm9uaWNhbF9mb3JtYXSUiIwTX2hhc19zb3J0ZWRfaW5kaWNlc5SIdWIu        |\n",
            "+------------+---------------------------------------------------------------------------+---------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_weighted_structural_similarity(csr_matrix_1, csr_matrix_2):\n",
        "    # Deserialize CSR matrices\n",
        "    csr_1 = pickle.loads(base64.b64decode(csr_matrix_1))\n",
        "    csr_2 = pickle.loads(base64.b64decode(csr_matrix_2))\n",
        "\n",
        "\n",
        "    # Align matrix dimensions to the largest size\n",
        "    max_rows = max(csr_1.shape[0], csr_2.shape[0])\n",
        "    max_cols = max(csr_1.shape[1], csr_2.shape[1])\n",
        "\n",
        "    # Pad csr_1 to match max dimensions\n",
        "    if csr_1.shape[0] < max_rows or csr_1.shape[1] < max_cols:\n",
        "        csr_1 = vstack([csr_1, csr_matrix((max_rows - csr_1.shape[0], csr_1.shape[1]))]) if csr_1.shape[0] < max_rows else csr_1\n",
        "        csr_1 = hstack([csr_1, csr_matrix((csr_1.shape[0], max_cols - csr_1.shape[1]))]) if csr_1.shape[1] < max_cols else csr_1\n",
        "\n",
        "    # Pad csr_2 to match max dimensions\n",
        "    if csr_2.shape[0] < max_rows or csr_2.shape[1] < max_cols:\n",
        "        csr_2 = vstack([csr_2, csr_matrix((max_rows - csr_2.shape[0], csr_2.shape[1]))]) if csr_2.shape[0] < max_rows else csr_2\n",
        "        csr_2 = hstack([csr_2, csr_matrix((csr_2.shape[0], max_cols - csr_2.shape[1]))]) if csr_2.shape[1] < max_cols else csr_2\n",
        "\n",
        "    # Calculate structural similarity (e.g., using cosine similarity)\n",
        "    dot_product = csr_1.multiply(csr_2).sum()\n",
        "    norm_1 = np.sqrt(csr_1.multiply(csr_1).sum())\n",
        "    norm_2 = np.sqrt(csr_2.multiply(csr_2).sum())\n",
        "    similarity = dot_product / (norm_1 * norm_2) if norm_1 != 0 and norm_2 != 0 else 0\n",
        "    return float(similarity)"
      ],
      "metadata": {
        "id": "q-64vmO6eNT0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import round # Import the round function from pyspark.sql.functions\n",
        "\n",
        "# Register UDF to compare structural similarity\n",
        "compare_structural_similarity_udf = udf(lambda csr_1, csr_2: compare_weighted_structural_similarity(csr_1, csr_2), DoubleType())\n",
        "compare_weighted_similarity_udf = udf(lambda csr_1, csr_2: compare_weighted_structural_similarity(csr_1, csr_2), DoubleType())\n",
        "\n",
        "# Cross join to compare each pair of communities and calculate both similarities\n",
        "cross_joined = community_members.alias(\"a\").crossJoin(community_members.alias(\"b\")) \\\n",
        "    .filter(col(\"a.community_id\") < col(\"b.community_id\")) \\\n",
        "    .withColumn(\"unweighted_similarity_score\", compare_structural_similarity_udf(col(\"a.csr_matrix_unweighted\"), col(\"b.csr_matrix_unweighted\"))) \\\n",
        "    .withColumn(\"weighted_similarity_score\", compare_weighted_similarity_udf(col(\"a.csr_matrix_weighted\"), col(\"b.csr_matrix_weighted\")))\n",
        "\n",
        "# Add combined similarity score (50/50 importance)\n",
        "cross_joined = cross_joined.withColumn(\"combined_similarity_score\",\n",
        "                                       0.5 * col(\"unweighted_similarity_score\") + 0.5 * col(\"weighted_similarity_score\"))\n",
        "\n",
        "# Show the similarity scores between communities\n",
        "cross_joined.select(col(\"a.community_id\").alias(\"community_id_1\"),\n",
        "                    col(\"b.community_id\").alias(\"community_id_2\"),\n",
        "                    round(col(\"unweighted_similarity_score\"), 2).alias(\"unweighted_similarity_score\"),  # Changed here\n",
        "                    round(col(\"weighted_similarity_score\"), 2).alias(\"weighted_similarity_score\"),  # Changed here\n",
        "                    round(col(\"combined_similarity_score\"), 2).alias(\"combined_similarity_score\")) \\\n",
        "      .orderBy([\"community_id_1\", \"community_id_2\"]) \\\n",
        "      .show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXw_Pfk5Q8zf",
        "outputId": "a1eb6d77-8d31-4206-871f-9e4a6e77639c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+---------------------------+-------------------------+-------------------------+\n",
            "|community_id_1|community_id_2|unweighted_similarity_score|weighted_similarity_score|combined_similarity_score|\n",
            "+--------------+--------------+---------------------------+-------------------------+-------------------------+\n",
            "|1             |2             |0.82                       |0.9                      |0.86                     |\n",
            "|1             |3             |0.82                       |0.81                     |0.82                     |\n",
            "|1             |4             |0.82                       |0.56                     |0.69                     |\n",
            "|2             |3             |1.0                        |0.98                     |0.99                     |\n",
            "|2             |4             |0.67                       |0.5                      |0.58                     |\n",
            "|3             |4             |0.67                       |0.45                     |0.56                     |\n",
            "+--------------+--------------+---------------------------+-------------------------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}